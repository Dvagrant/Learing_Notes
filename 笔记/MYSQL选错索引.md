化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。

在数据库里面，`扫描行数`是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。

当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。

---
## 扫描行数的判断
MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。

这个统计信息就是索引的`区分度`。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为`基数（cardinality）`。也就是说，这个基数越大，索引的区分度越好。

我们可以使用`show index`方法，看到一个索引的基数。
MySQL 通过采样统计得到索引的基数。

为什么要采样统计呢？因为把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”。采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。

在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数` innodb_stats_persistent`的值来选择：
- 设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。
- 设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。

explain中的执行计划`rows`这个字段表示的是预计扫描行数。
慢查询日志中的`rows_examined`表示真实扫描行数。

> 在不断删除历史数据同时新增数据的场景下，由于存在事务未提交的情况，逻辑删除的索引无法物理删除（存在未提交事务的MVCC一致性视图），会造成优化器错误判断索引的基数，从而走了代价更高的错误计划。

`analyze table t`命令，可以用来重新统计索引信息。
所以在实践中，如果你发现 explain 的结果预估的 rows 值跟实际情况差距比较大，可以采用这个方法来处理。

---
## 选错索引时的应对方法
原本可以执行得很快的 SQL 语句，执行速度却比你预期的慢很多，你应该怎么办呢？

### 第一种办法
采用 force index 强行选择一个索引。MySQL 会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在候选列表中依次判断每个索引需要扫描多少行。如果 force index 指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。

### 第二种方法
可以考虑修改语句，引导 MySQL 使用我们期望的索引。

> select \* from t where (a between 1 and 1000) and (b between 50000 and 100000) `order by b limit 1`
>
> select \* from t where (a between 1 and 1000) and (b between 50000 and 100000) `order by b,a limit 1`

使用`order by b`时，由于索引是有序的，所以优化器认为使用b索引可以避免排序，即使扫描行数多，也会判定为代价更小。
修改为`order by b,a`，意味着两个索引都需要排序，这是扫描行数便成了影响决策的关键，a 索引的谓词条件扫描行数小，便选择了 a 索引。

> select \* from  (select \* from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 100)alias limit 1

写`limit 100`使优化器意识到使用 b 的代价很高。
*** limit 了之后，它就知道最多取100条数据。当看到b的第一步扫描要比a的第一步扫描多这么多，而多出来的这些都不会进入第二次扫描(因为只取前100条)，mysql就会选择a做索引来减少第一次扫描的量。***

### 第三种方法
，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。